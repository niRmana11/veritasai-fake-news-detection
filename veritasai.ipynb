{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from logging import warning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ],
   "id": "40aeaa8f6c26debb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load data\n",
    "data = pd.read_csv(\"data/latest_news.csv\")\n",
    "\n",
    "\n",
    "print(\"Initial shape:\", data.shape)\n",
    "data.head()"
   ],
   "id": "af280b81ddcb6de6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# keep relevant columns\n",
    "data = data[['title', 'text', 'label']]\n",
    "\n",
    "# remove missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "print(\"After cleaning:\", data.shape)\n",
    "data.head()"
   ],
   "id": "42a84a0c251298af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# encode labels\n",
    "label_map = {'FAKE': 0, 'REAL': 1}\n",
    "data['label'] = data['label'].map(label_map)\n",
    "\n",
    "print(\"Label distribution:\")\n",
    "print(data['label'].value_counts())"
   ],
   "id": "37eb7ece409f221a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# combine title and text\n",
    "data['content'] = data['title'].astype(str) + \" \" + data['text'].astype(str)\n",
    "\n",
    "X = data['content']\n",
    "y = data['label']"
   ],
   "id": "ac0e30cde10b6f35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# split train/test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0])\n",
    "print(\"Test size:\", X_test.shape[0])"
   ],
   "id": "64a1d64ee7641e6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=3,\n",
    "    max_df=0.9\n",
    ")\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF feature size:\", X_train_tfidf.shape[1])\n"
   ],
   "id": "caedcd8910104182",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train model\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver=\"liblinear\"\n",
    ")\n",
    "\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"VeritasAI model trained\")"
   ],
   "id": "720d2b11c4043f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# evaluate model\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ],
   "id": "f6fe20179b7c290e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# save model and vectorizer\n",
    "\n",
    "with open(\"veritasai_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open(\"veritasai_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "with open(\"label_map.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_map, f)\n",
    "\n",
    "print(\"Model, vectorizer, and label map saved\")"
   ],
   "id": "b2d5971434adf0ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load and test saved model\n",
    "with open(\"veritasai_model.pkl\", \"rb\") as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "with open(\"veritasai_vectorizer.pkl\", \"rb\") as f:\n",
    "    loaded_vectorizer = pickle.load(f)\n",
    "\n",
    "with open(\"label_map.pkl\", \"rb\") as f:\n",
    "    label_map = pickle.load(f)\n",
    "\n",
    "inverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# realistic test sample\n",
    "sample_title = \"Mexico president asks South Korea for more BTS concerts\"\n",
    "sample_text = (\n",
    "    \"The scramble for tickets to K-pop band BTS' comeback tour, which comes after a four-year hiatus, has seen Mexico's president appealing to her South Korean counterpart to add more shows in her country. 'I wrote a letter to the [president] of Korea... I still haven't received the answer, but let's hope it's positive,' Mexico's president Claudia Sheinbaum said on Monday. BTS will hold three shows in Mexico City in May, as part of its 79-date world tour after a four-year hiatus. Tickets were wiped out in less than 40 minutes, local media reported. Some fans have also accused Ticketmaster and resale platforms of dynamic pricing, prompting an investigation.\"\n",
    ")\n",
    "\n",
    "sample_content = sample_title + \" \" + sample_text\n",
    "\n",
    "sample_tfidf = loaded_vectorizer.transform([sample_content])\n",
    "\n",
    "print(\"Non-zero features:\", sample_tfidf.nnz)\n",
    "\n",
    "prediction = loaded_model.predict(sample_tfidf)\n",
    "probabilities = loaded_model.predict_proba(sample_tfidf)\n",
    "\n",
    "print(\"Prediction:\", inverse_label_map[prediction[0]])\n",
    "print(\"Confidence (FAKE, REAL):\", probabilities[0])\n",
    "\n",
    "real_conf = probabilities[0][1]\n",
    "\n",
    "if real_conf > 0.7:\n",
    "    verdict = \"Likely REAL\"\n",
    "elif real_conf < 0.3:\n",
    "    verdict = \"Likely FAKE\"\n",
    "else:\n",
    "    verdict = \"UNCERTAIN\"\n",
    "\n",
    "print(\"Verdict:\", verdict)\n",
    "\n",
    "if sample_tfidf.nnz < 40:\n",
    "    warning = \"Text may be outside training domain\"\n",
    "    print(warning)\n"
   ],
   "id": "c1292e457706434a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(\"latest_news.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "print(\"Latest news dataset saved as PKL\")"
   ],
   "id": "6a5c6aa9a80b27aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(\"latest_news.pkl\", \"rb\") as f:\n",
    "    latest_data = pickle.load(f)\n",
    "\n",
    "print(latest_data.shape)\n",
    "latest_data.head()"
   ],
   "id": "dd810970946ce56b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_pred = model.predict(X_train_tfidf)\n",
    "\n",
    "print(\"Train accuracy:\", accuracy_score(y_train, train_pred))\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))\n"
   ],
   "id": "3e2a3129b93c3a8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# remove exact duplicate articles\n",
    "before = data.shape[0]\n",
    "\n",
    "data = data.drop_duplicates(subset=[\"content\"])\n",
    "\n",
    "after = data.shape[0]\n",
    "print(f\"Removed {before - after} duplicate rows\")\n"
   ],
   "id": "5fef68e4675eb9e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
   "id": "891cee422505060c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "leakage_words = [\n",
    "    \"reuters\", \"associated press\", \"fact check\",\n",
    "    \"fake news\", \"snopes\", \"politifact\"\n",
    "]\n",
    "\n",
    "pattern = \"|\".join(leakage_words)\n",
    "\n",
    "data[\"content\"] = data[\"content\"].str.replace(\n",
    "    pattern, \"\", case=False, regex=True\n",
    ")\n"
   ],
   "id": "cd29b9b540ea7f3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data[\"content\"]\n",
    "y = data[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ],
   "id": "2269951d1da632ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    max_df=0.85\n",
    ")\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ],
   "id": "1bd611420ca7fc86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    C=0.3,              # stronger regularization\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(X_train_tfidf, y_train)\n"
   ],
   "id": "51f9b4ae2dd27ba8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_pred = model.predict(X_train_tfidf)\n",
    "test_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Train accuracy:\", accuracy_score(y_train, train_pred))\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, test_pred))\n"
   ],
   "id": "43f8938921126b87",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
